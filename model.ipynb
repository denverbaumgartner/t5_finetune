{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e63b061c-10c3-4b76-931e-37bb54935f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "print('hello, world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6b99348c-01f4-4a6b-bfca-19f67e2cd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "814a2ef6-6806-4016-b571-ea6c396593c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model_dir = \"model/\"\n",
    "k_test_file = \"data/test.source\"\n",
    "k_test_path = \"test/\"\n",
    "\n",
    "k_base_model = \"mrm8488/t5-base-finetuned-wikiSQL\" \n",
    "k_base_model_name = \"t5-base-finetuned-wikiSQL\"\n",
    "k_base_tokenizer = \"mrm8488/t5-base-finetuned-wikiSQL\" \n",
    "k_tune_tokenizer = \"tokenizer/spider_original-01\"\n",
    "\n",
    "with open(k_test_file, \"r\") as file: \n",
    "    k_test = file.readlines()\n",
    "\n",
    "k_model_dirs = [f for f in os.listdir(k_model_dir) if os.path.isdir(os.path.join(k_model_dir, f))]\n",
    "k_model_paths = [os.path.join(k_model_dir, model_dir) for model_dir in k_model_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88ec528f-d70f-4152-a02f-b3233db92dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_in_batches(model, tokenizer, test_data, batch_size):\n",
    "    predictions = []\n",
    "    total_batches = len(test_data) // batch_size + (1 if len(test_data) % batch_size else 0)\n",
    "\n",
    "    for i in tqdm(range(total_batches), desc=\"Processing\", unit=\"batch\"):\n",
    "        batch = test_data[i * batch_size:(i + 1) * batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        output_ids = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_length=512, no_repeat_ngram_size=2)\n",
    "        batch_predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in output_ids]\n",
    "        predictions.extend(batch_predictions)\n",
    "    return predictions\n",
    "\n",
    "def test_model(test_data, model_path, tokenizer_path, test_path, model_name, batch_size, mock=False): \n",
    "\n",
    "    if mock: \n",
    "        write_path = f\"{test_path}{model_name}.txt\"\n",
    "        print(f\"model: {model_path}, tokenizer: {tokenizer_path}, test_path: {test_path}, model_name: {model_name}, write_path: {write_path}\")\n",
    "    else: \n",
    "        print(f\"loading model from path: {model_path}\")\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "        tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
    "        predictions = process_in_batches(model, tokenizer, test_data, batch_size)\n",
    "    \n",
    "        with open(f\"{test_path}{model_name}.txt\", \"w\") as file: \n",
    "            for pred in predictions:\n",
    "                file.write(pred + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dabf0c27-fe08-498f-ac04-9315e9ac9acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: mrm8488/t5-base-finetuned-wikiSQL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Processing: 100%|██████████| 109/109 [09:27<00:00,  5.20s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:17<00:00,  2.92s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:34<00:00,  3.07s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:06<00:00,  3.36s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:31<00:00,  3.04s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:40<00:00,  3.13s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:15<00:00,  3.45s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:25<00:00,  3.54s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:15<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:51<00:00,  3.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:06<00:00,  3.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:44<00:00,  3.16s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:38<00:00,  3.11s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:02<00:00,  3.32s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:32<00:00,  3.05s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:36<00:00,  3.09s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:47<00:00,  3.19s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [06:21<00:00,  3.50s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:42<00:00,  3.14s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:53<00:00,  3.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:48<00:00,  3.20s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:55<00:00,  3.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:43<00:00,  3.15s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:47<00:00,  3.19s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:54<00:00,  3.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/spider_original-49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:56<00:00,  3.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:25<00:00,  2.99s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:31<00:00,  3.04s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:28<00:00,  3.02s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:08<00:00,  2.83s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:41<00:00,  3.13s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:46<00:00,  3.18s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:30<00:00,  3.03s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:25<00:00,  2.99s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:05<00:00,  2.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:25<00:00,  2.99s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:52<00:00,  3.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [04:59<00:00,  2.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:09<00:00,  2.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:01<00:00,  2.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:12<00:00,  2.86s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:27<00:00,  3.01s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:01<00:00,  2.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:17<00:00,  2.92s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:14<00:00,  2.89s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [04:58<00:00,  2.74s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:11<00:00,  2.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:04<00:00,  2.79s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:10<00:00,  2.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:29<00:00,  3.02s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path: model/synthetic_joint-49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing: 100%|██████████| 109/109 [05:26<00:00,  3.00s/batch]\n"
     ]
    }
   ],
   "source": [
    "mock = False\n",
    "test_model(\n",
    "    test_data=k_test, \n",
    "    model_path=k_base_model, \n",
    "    tokenizer_path=k_base_tokenizer, \n",
    "    test_path=k_test_path, \n",
    "    model_name=k_base_model_name, \n",
    "    batch_size=8, \n",
    "    mock=mock\n",
    ")\n",
    "\n",
    "for i in range(len(k_model_dirs)): \n",
    "    model_path = k_model_paths[i]\n",
    "    model_name = k_model_dirs[i]\n",
    "    \n",
    "    test_model(\n",
    "        test_data=k_test, \n",
    "        model_path=model_path, \n",
    "        tokenizer_path=k_tune_tokenizer, \n",
    "        test_path=k_test_path, \n",
    "        model_name=model_name, \n",
    "        batch_size=8, \n",
    "        mock=mock\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ab87725d-36dd-4517-a374-1570fdecace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n",
      "260\n",
      "mismatch\n",
      "The models are different.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load the models from the saved checkpoint directories\n",
    "model1 = T5ForConditionalGeneration.from_pretrained('model/synthetic_joint-01')\n",
    "model2 = T5ForConditionalGeneration.from_pretrained('model/synthetic_joint-49')\n",
    "\n",
    "# Function to compare two models\n",
    "def are_models_identical(model1, model2):\n",
    "    model1_dict = model1.state_dict()\n",
    "    model2_dict = model2.state_dict()\n",
    "    print(len(model1_dict))\n",
    "    print(len(model2_dict))\n",
    "\n",
    "    if set(model1_dict.keys()) != set(model2_dict.keys()):\n",
    "        # Different sets of parameters\n",
    "        return False\n",
    "\n",
    "    count = 0 \n",
    "    for param in model1_dict:\n",
    "        if not torch.equal(model1_dict[param], model2_dict[param]):\n",
    "            # Found a mismatch\n",
    "            count += 1\n",
    "            print('mismatch')\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Check if the models are the same\n",
    "are_same = are_models_identical(model1, model2)\n",
    "\n",
    "print(f\"The models are {'the same' if are_same else 'different'}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_notebook",
   "language": "python",
   "name": "model_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
